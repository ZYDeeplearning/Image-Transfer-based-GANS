{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random\nimport torch\nimport glob as gl\nimport os\nimport random\nimport numpy as np\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchvision.transforms import InterpolationMode\nimport cv2\nimport matplotlib.pyplot as plt\n#定义数据集\nclass ImageDataset(Dataset):\n    def __init__(self,root='',trans=None,mode=None):\n        super().__init__()\n        self.transform = transforms.Compose(trans)\n\n        self.TA_path = os.path.join(root,\"trainA/*\")\n        self.TB_path = os.path.join(root,\"trainB/*\")\n        self.EA_path = os.path.join(root, \"edgeA/*\")\n        self.EB_path = os.path.join(root, \"edgeB/*\")\n        if mode == 'A':\n            self.source_path = os.path.join(root, \"sourceA/*\")\n        else:\n            self.source_path=os.path.join(root,'sourceB/*')\n        self.list_TA = gl.glob(self.TA_path)\n        self.list_TB = gl.glob(self.TB_path)\n        self.list_EA = gl.glob(self.EA_path)\n        self.list_EB = gl.glob(self.EB_path)\n        self.list_source = gl.glob(self.source_path)\n\n    def  __getitem__ (self, index):\n        data = {}\n        imgTA_path = random.choice(self.list_TA)\n        imgTB_path = random.choice(self.list_TB)\n        imgEA_path = random.choice(self.list_EA)\n        imgEB_path = random.choice(self.list_EB)\n        img_path = random.choice(self.list_source)\n        imgTA = Image.open(imgTA_path).convert('RGB')\n        imgTB = Image.open(imgEB_path).convert('RGB')\n        imgEA= Image.open(imgEA_path).convert('RGB')\n        imgEB = Image.open(imgEB_path).convert('RGB')\n        img = Image.open(img_path).convert('RGB')\n        img=self.transform(img)\n        img_A = self.transform(imgTA)\n        img_B = self.transform(imgTB)\n        img_C = self.transform(imgEA)\n        img_D = self.transform(imgEB)\n        data.update({'source':img,'TA':img_A,'TB':img_B,'EA':img_C,'EB':img_D})\n        return data\n    def __len__(self):\n        return max(len(self.list_TA),len(self.list_TB),len(self.list_EA),len(self.list_EB),len(self.list_source))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time as t\nimport os\nimport random\nimport numpy as np\nimport torch\nfrom torch.autograd import Variable\n#初始化\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        m.weight.data.normal_(0.0, 0.02)\n        if hasattr(m.bias, 'data'):\n            m.bias.data.fill_(0)\n    elif classname.find('BatchNorm2d') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        m.bias.data.fill_(0)\n#时间转化\ndef time_change(time):\n    new_time = t.localtime(time)\n    new_time = t.strftime(\"%Hh%Mm%Ss\", new_time)\n    return new_time\n#归一化\ndef  denorm(x):\n    x=(x* 0.5+ 0.5)*255.0\n    return x.cpu().detach().numpy().transpose(1,2,0)\ndef RGB2BGR(x):\n    return cv2.cvtColor(x, cv2.COLOR_RGB2BGR)\n#创建文件目录\ndef check_folder(log_dir):\n    if not os.path.exists(log_dir):\n        os.makedirs(log_dir)\n    return log_dir\n#图片池\n\nclass ImagePool():\n    def __init__(self, pool_size):\n        self.pool_size = pool_size\n        if self.pool_size > 0:\n            self.num_imgs = 0\n            self.images = []\n\n    def query(self, images):\n        if self.pool_size == 0:\n            return images\n        return_images = []\n        for image in images.data:\n            image = torch.unsqueeze(image, 0)\n            if self.num_imgs < self.pool_size:\n                self.num_imgs = self.num_imgs + 1\n                self.images.append(image)\n                return_images.append(image)\n            else:\n                p = random.uniform(0, 1)\n                if p > 0.5:\n                    random_id = random.randint(0, self.pool_size-1)\n                    tmp = self.images[random_id].clone()\n                    self.images[random_id] = image\n                    return_images.append(tmp)\n                else:\n                    return_images.append(image)\n        return_images = Variable(torch.cat(return_images, 0))\n        return return_images","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torchvision import transforms\nfrom torchvision.transforms import InterpolationMode\nfrom torch.utils.data  import DataLoader\nfrom tqdm import tqdm\nimport numpy  as np\n#定义残差块\nclass ResBlock(nn.Module):\n          def __init__(self,channels,use_bias=False):\n                  super().__init__()\n                  Res_block=[]\n                  Res_block+=[nn.ReflectionPad2d(1),\n                              nn.Conv2d(channels,channels,3,1,0,bias=use_bias),\n                              nn.InstanceNorm2d(channels),nn.PReLU(num_parameters=1)]\n                      \n                  Res_block+=[nn.ReflectionPad2d(1),\n                              nn.Conv2d(channels,channels,3,1,0,bias=use_bias),\n                              nn.InstanceNorm2d(channels)]\n                  self.Res_block=nn.Sequential(*Res_block)\n          def forward(self,x):\n                    return x+self.Res_block(x)\n#定义生成器-Encoder\nclass GenEncoder(nn.Module):\n          def __init__(self,hw=64,n_block=None,norm=nn.InstanceNorm2d,use_bias=False):\n                  super().__init__()\n                  #平面卷积\n                  model=[]\n                  model+=[nn.ReflectionPad2d(3),\n                    nn.Conv2d(3,hw,7,1,0,bias=use_bias)]\n                  #下采样\n                  down=2\n                  for i in range(down):\n                      mult=2**i\n                      model+=[nn.Conv2d(hw*mult,hw*mult*2,kernel_size=3,stride=2,padding=1,bias=use_bias),\n                                  norm(hw*mult*2),nn.ReLU(True)] \n                  #残差块\n                  res=hw*4           \n                  for j in range(n_block):\n                      model+=[ResBlock(res)]\n                  self.model=nn.Sequential(*model) \n          def forward(self,x):\n                    return self.model(x)   #1,256,64,64        \n#定义解码器\nclass GenDecoder(nn.Module):\n          def __init__(self,hw=64,out_channels=3,n_block=None,norm=nn.InstanceNorm2d,use_bias=False):\n                  super().__init__()\n                  #残差块\n                  model=[]\n                  res=hw*4\n                  for i in range(n_block):\n                    model+=[ResBlock(res)]\n                  # frist upsample\n                  mult=2**(n_block//2)\n                  model += [nn.Upsample(scale_factor=2, mode='bilinear'),\n                    nn.Conv2d(int(hw * mult), int(hw * mult / 2), kernel_size=3, stride=1, padding=1),\n                    nn.Conv2d(int(hw * mult / 2), int(hw * mult / 2), kernel_size=3, stride=1, padding=1),\n                              norm(int(hw * mult / 2)),\n                              nn.ReLU(True)]\n                  # second upsampling\n                  model += [nn.Upsample(scale_factor=2, mode='bilinear'),\n                    nn.Conv2d(int(hw * mult / 2), int(hw * mult / 4), kernel_size=3, stride=1, padding=1),\n                    nn.Conv2d(int(hw * mult / 4), int(hw * mult / 4), kernel_size=3, stride=1, padding=1),\n                              norm(int(hw * mult / 4)),\n                              nn.ReLU(True)]\n                  #addtional layer\n                  model+=[nn.Conv2d(int(hw*mult/4),int(hw*mult/8),kernel_size=3,stride=1,padding=1),\n                           nn.Conv2d(int(hw*mult/8),int(hw*mult/8),kernel_size=3,stride=1,padding=1),\n                           norm(int(hw*mult/8)),nn.ReLU(True)]    \n                  model+=[nn.Conv2d(int(hw*mult/8),int(hw*mult/16),kernel_size=3,stride=1,padding=1),\n                              nn.Conv2d(int(hw*mult/16),int(hw*mult/16),kernel_size=3,stride=1,padding=1),\n                              norm(int(hw*mult/16)),nn.ReLU(True)]  \n                  model+=[nn.Conv2d(int(hw*mult/16),out_channels,7,1,3),nn.Tanh()]  \n                  self.model=nn.Sequential(*model)\n          def forward(self,x):\n                    return self.model(x)                  \n#定义生成器               \nclass Generator(nn.Module):\n          def __init__(self,n_domian=None,E_block=5,D_block=4):\n                  super(Generator,self).__init__()\n                  #编码器\n                  self.Encoder=[GenEncoder(n_block=E_block)]\n                  self.Encoder=nn.Sequential(*self.Encoder)\n                  #解码器\n                  self.Decoder1=[GenDecoder(n_block=D_block)]\n                  self.Decoder2=[GenDecoder(n_block=D_block)]\n                  self.Decoder1=nn.Sequential(*self.Decoder1)\n                  self.Decoder2=nn.Sequential(*self.Decoder2)\n          def encoder(self,x):\n                    return self.Encoder(x)  # type: ignore\n          def decoders(self,x,n):\n                    if n==0:\n                       return self.Decoder1(x)\n                    else :\n                        return self.Decoder2(x)\n          def forward(self,x,n):\n                encode=self.encoder(x)\n                return self.decoders(encode,n)\n#patchgan  \nclass PatchGAN_D(nn.Module):\n          def __init__(self,hw=64,out_channels=3,norm=nn.InstanceNorm2d,use_bias=False):\n                  super(PatchGAN_D,self).__init__()\n                  model=[]\n                  #平面卷积\n                  model+=[nn.Conv2d(out_channels,hw,kernel_size=3,stride=1,padding=1,bias=True),\n                          nn.LeakyReLU(0.2,True)\n                  ]\n                  #下采样\n                  model+=[nn.Conv2d(hw,hw*2,kernel_size=3,stride=2,padding=1,bias=True),\n                              nn.LeakyReLU(0.2,True),nn.Conv2d(hw*2,hw*4,kernel_size=3,stride=1,padding=1,bias=True),\n                              norm(hw*4),nn.LeakyReLU(0.2,True),\n                              nn.Conv2d(hw*4,hw*4,kernel_size=3,stride=2,padding=1,bias=True),\n                              nn.LeakyReLU(0.2,True),nn.Conv2d(hw*4,hw*8,kernel_size=3,stride=1,padding=1,bias=True),\n                              norm(hw*8),nn.LeakyReLU(0.2,True),\n                              nn.Conv2d(hw*8,1,kernel_size=3,stride=1,padding=1),nn.Sigmoid()\n                              ]\n                  self.model=nn.Sequential(*model)\n          def forward(self,x):\n                    return self.model(x)\n\n\n#判别器结构patchGAN\nclass Discrimintor1(nn.Module):\n          def __init__(self):\n                  super(Discrimintor1,self).__init__()\n                  self.model=[PatchGAN_D()]\n                  self.model=nn.Sequential(*self.model)\n                 \n          def forward(self,x):\n                return self.model(x)\n          def init_train(self,grad=None):\n              for param in self.model.parameters():\n                  param.requires_grad = grad\nclass Discrimintor2(nn.Module):\n          def __init__(self):\n                  super(Discrimintor2,self).__init__()\n                  self.model=[PatchGAN_D()]\n                  self.model=nn.Sequential(*self.model)\n          def forward(self,x):\n                return self.model(x)\n          def init_train(self,grad=None):\n              for param in self.model.parameters():\n                  param.requires_grad = grad                \n#aux classfier                  \nclass aux_classfier(nn.Module):\n    def __init__(self,dim=32,num_class=None,use_bias=False):\n        super().__init__()\n        #平面卷积\n        layer=[]\n        layer+=[nn.Conv2d(3,dim,kernel_size=4,stride=2,padding=1),\n                nn.LeakyReLU(0.01,True)]\n        for i in range(4):\n            mult=2**i\n            layer+=[nn.Conv2d(dim*mult,dim*mult*2,kernel_size=4,stride=2,padding=1),\n                    nn.LeakyReLU(0.01,True)]\n        # j=int(256/np.power(2,4))\n        layer+=[nn.Conv2d(512,num_class,kernel_size=8,bias=use_bias)]\n        self.layer=nn.Sequential(*layer)\n    def forward(self,x):\n        out=self.layer(x)\n        return out.view(out.size(0),out.size(1))\n    def init_train(self,grad=None):\n            for param in self.layer.parameters():\n                param.requires_grad = grad\n\n#VGG19\nclass VGG19(nn.Module):\n    def __init__(self,batch_norm=False,num_classes=1000):\n        super(VGG19, self).__init__()\n        self.cfg = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512,\n                    'M']\n        self.batch_norm=batch_norm\n        self.num_clases = num_classes\n        self.features=self.make_layers(self.cfg,self.batch_norm)\n        self.classifier = nn.Sequential(\n            nn.Linear(512 * 7 * 7, 4096),\n            nn.ReLU(True),\n            nn.Dropout(),\n            nn.Linear(4096, 4096),\n            nn.ReLU(True),\n            nn.Dropout(),\n            nn.Linear(4096, num_classes),\n        )\n    def make_layers(self, cfg, batch_norm=False):\n        layers = []\n        in_channels = 3\n        for v in cfg:\n            if v == 'M':\n                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n            else:\n                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n                if batch_norm:\n                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n                else:\n                    layers += [conv2d, nn.ReLU(inplace=True)]\n                in_channels = v\n        return nn.Sequential(*layers)\n    def forward(self,x):\n        module_list = list(self.features.modules())\n        for l in module_list[1:27]:  # conv4_4\n            x = l(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport torch\nfrom torch import optim\nimport itertools\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\nfrom torch.nn.functional import interpolate\nimport cv2\nimport numpy as np\nclass MSCartoonGAN(object):\n    def __init__(self,args):\n        #定义配置\n        self.device=args.device\n        self.dir=args.dir\n        self.dataset=args.dataset\n        self.data_path=args.data_path\n        self.test_path=args.test_path\n        self.isTrain=args.isTrain\n        self.isTest = args.isTest\n        self.train_init=args.train_init\n        self.n_domains=args.n_domain\n        #定义模型参数\n        self.input_c=args.input_c\n        self.hw=args.hw\n        self.b1=args.b1\n        self.b2=args.b2\n        self.lr=args.lr\n        self.init_lr=args.init_lr\n        self.batch_size=args.batch_size\n        self.save_pred=args.save_pred\n        self.iter=args.iter\n        self.weight_content=args.weight_content\n        self.weight_classifer=args.weight_classifer\n        self.weight_decay=args.weight_decay\n        self.mode=args.mode\n        #定义模型\n        self.G=Generator(args.n_domain).to(self.device)\n        self.D1=Discrimintor1().to(self.device)\n        self.D2=Discrimintor2().to(self.device)\n        self.classifier=aux_classfier(num_class=args.n_class).to(self.device)\n        self.vgg19=VGG19().to(self.device)\n        #模型初始化\n        self.G.apply(weights_init)\n        self.D1.apply(weights_init)\n        self.D2.apply(weights_init)\n        self.classifier.apply(weights_init)\n        self.vgg19.load_state_dict(torch.load('/kaggle/input/vgg19-model/vgg19.pth'))\n        #优化器策略\n        if self.train_init:\n           self.G_optim=optim.Adam(self.G.parameters(),lr=self.init_lr,betas=(self.b1,self.b2))\n        else:\n           self.G_optim=optim.Adam(self.G.parameters(),lr=self.lr,betas=(self.b1,self.b2))\n        self.D1_optim=optim.Adam(self.D1.parameters(),lr=self.lr,betas=(self.b1,self.b2))\n        self.D2_optim=optim.Adam(self.D2.parameters(),lr=self.lr,betas=(self.b1,self.b2))\n        self.classifier_optim=optim.Adam(self.classifier.parameters(),lr=self.lr,betas=(self.b1,self.b2))\n        #定义损失函数\n        self.lcon=nn.L1Loss().to(self.device)\n        self.ladv=nn.BCELoss().to(self.device)\n        self.lsty=nn.CrossEntropyLoss().to(self.device)\n        self.lambda_con = self.weight_content\n        self.lambda_cla = self.weight_classifer\n        # 定义标签\n        self.real_img = torch.cuda.FloatTensor(self.batch_size, self.input_c, self.hw, self.hw)\n        self.real_A = torch.cuda.FloatTensor(self.batch_size, self.input_c, self.hw, self.hw)\n        self.real_B = torch.cuda.FloatTensor(self.batch_size, self.input_c, self.hw, self.hw)\n        # edge\n        self.edge_A = torch.cuda.FloatTensor(self.batch_size, self.input_c, self.hw, self.hw)\n        self.edge_B = torch.cuda.FloatTensor(self.batch_size, self.input_c, self.hw, self.hw)\n        #图片池\n        self.fake_pools = [ImagePool(args.pool_size) for _ in range(self.n_domains)]\n    #加载数据集\n    def load_data(self,mode=None):\n        trans=[transforms.Resize(286,InterpolationMode.BICUBIC),\n               transforms.CenterCrop(256),\n               transforms.RandomHorizontalFlip(0.5),\n               transforms.ToTensor(),\n               transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))]\n        data_loader=DataLoader(ImageDataset(root=self.data_path,trans=trans,mode=self.mode),batch_size=self.batch_size,drop_last=True,shuffle=True)\n        return data_loader\n    #设置输入  \n    def set_input(self, input):  # input is a dictionary recording images\n        input_real = input['source'].to(self.device)\n        self.real_img.resize_(input_real.size()).copy_(input_real).to(self.device)\n        input_A = input['TA'].to(self.device)\n        self.real_A.resize_(input_A.size()).copy_(input_A).to(self.device)\n        input_B = input['TB'].to(self.device)\n        self.real_B.resize_(input_B.size()).copy_(input_B).to(self.device)\n        # for images without edges\n        edge_EA = input['EA'].to(self.device)\n        self.edge_A.resize_(edge_EA.size()).copy_(edge_EA).to(self.device)\n        edge_EB = input['EB'].to(self.device)\n        self.edge_B.resize_(edge_EB.size()).copy_(edge_EB).to(self.device)\n    #生成假图.to(self.device)\n    def Gen_pool(self):\n        encode=self.G.encoder(self.real_img)\n        self.fake_a=self.G.decoders(encode,0).clone()\n        self.fake_b=self.G.decoders(encode,1).clone()\n    def Gen_pool_test(self,input):\n        encode=self.G.encoder(input)\n        fake_a=self.G.decoders(encode,0).clone()\n        fake_b=self.G.decoders(encode,1).clone()    \n        return fake_a,fake_b\n    #训练\n    def train(self):\n        #输入设置\n        start_time=t.time()\n        data_loader=self.load_data()\n        print(\"----------------------train start!----------------\")\n        print(\"------------init paser!-----------------------\")\n        for step in tqdm(range(1,self.iter+1)):\n            self.G.train()\n            for i ,data in enumerate(data_loader):\n                count=len(data_loader)\n                self.set_input(data)\n                if not self.train_init:\n                    self.D1.train()\n                    self.D2.train()\n                    self.classifier.train()\n                    self.D1.init_train(True)\n                    self.D2.init_train(True)\n                    self.classifier.init_train(True)\n                    #训练判别器\n                    self.D1_optim.zero_grad()\n                    self.D2_optim.zero_grad()\n                    self.classifier_optim.zero_grad()\n                    self.Gen_pool()  # 生成假图\n                    #对抗损失\n                    fake_a=self.fake_pools[0].query(self.fake_a)\n                    fake_b=self.fake_pools[1].query(self.fake_b)\n                    #real\n                    real_a=self.D1(self.real_A)\n                    real_a_logit=self.ladv(real_a,torch.ones_like(real_a))\n                    real_b = self.D2(self.real_B)\n                    real_b_logit = self.ladv(real_b, torch.ones_like(real_b))\n                    #edge\n                    edge_a = self.D1(self.edge_A)\n                    edge_a_logit = self.ladv(edge_a, torch.zeros_like(edge_a))\n                    edge_b = self.D2(self.edge_B)\n                    edge_b_logit = self.ladv(real_b, torch.zeros_like(edge_b))\n                    # fake\n                    fake_a = self.D1(fake_a.detach())\n                    fake_a_logit = self.ladv(fake_a, torch.zeros_like(fake_a))\n                    fake_b = self.D2(fake_b)\n                    fake_b_logit = self.ladv(fake_b, torch.zeros_like(fake_b))\n                    #class loss\n                    class_real_a=self.classifier(self.real_A)\n                    label_real_a=torch.cuda.FloatTensor(class_real_a.size()[0]).fill_(0).long()\n                    class_a_logit=self.lsty(class_real_a,label_real_a)\n                    class_real_b=self.classifier(self.real_B)\n                    label_real_b=torch.cuda.FloatTensor(class_real_b.size()[0]).fill_(1).long()\n                    class_b_logit = self.lsty(class_real_b,label_real_b)\n                    class_edge_a= self.classifier(self.edge_A)\n                    label_a=torch.cuda.FloatTensor(class_edge_a.size()[0]).fill_(2).long()\n                    class_edge_logitA = self.lsty(class_edge_a,label_a)\n                    class_edge_b = self.classifier(self.edge_B)\n                    label_b = torch.cuda.FloatTensor(class_edge_b.size()[0]).fill_(2).long()\n                    class_edge_logitB = self.lsty(class_edge_b, label_b)\n                    #各个风格的loss\n                    loss_D1=(real_a_logit+edge_a_logit+fake_a_logit)/3+(class_edge_logitA+class_a_logit)/2*self.lambda_cla\n                    loss_D2=(real_b_logit+edge_b_logit+fake_b_logit)/3+(class_edge_logitB+class_b_logit)/2*self.lambda_cla\n                    #传播更新\n                    loss_D1.backward()\n                    loss_D2.backward()\n                    self.D1_optim.step()\n                    self.D2_optim.step()\n                    #训练生成器\n                    self.G_optim.zero_grad()\n                    self.Gen_pool()#产生假图\n                    #adv loss\n                    fake_g_a=self.D1(self.fake_a)\n                    label_fake_a=torch.cuda.FloatTensor(fake_g_a.size()).fill_(1)\n                    fake_a_g_logit=self.ladv(fake_g_a,label_fake_a)\n                    fake_g_b = self.D2(self.fake_b)\n                    label_fake_b=torch.cuda.FloatTensor(fake_g_b.size()).fill_(1)\n                    fake_b_g_logit = self.ladv(fake_g_b,label_fake_b)\n                    #class loss\n                    class_ga_logit=self.classifier(self.fake_a)\n                    label_class_a=torch.cuda.FloatTensor(class_ga_logit.size()[0]).fill_(0).long()\n                    class_ga_logit=self.lsty(class_ga_logit,label_class_a)\n                    class_gb_logit = self.classifier(self.fake_b)\n                    label_class_b=torch.cuda.FloatTensor(class_gb_logit.size()[0]).fill_(1).long()\n                    class_gb_logit = self.lsty(class_gb_logit,label_class_b)\n                #content loss\n                #256*256\n                self.D1.init_train(grad=False)\n                self.D2.init_train(grad=False)\n                self.classifier.init_train(grad=False)\n                self.Gen_pool()  # 产生假图\n                real_con1=self.vgg19(self.real_img)\n                fake_con1_a=self.vgg19(self.fake_a)\n                loss_con1_a=self.lcon(fake_con1_a,real_con1.detach())\n                fake_con1_b = self.vgg19(self.fake_b)\n                loss_con1_b= self.lcon(fake_con1_b,real_con1.detach())\n                #128*128\n                real_con2=interpolate(self.real_img,scale_factor=0.5,mode='bilinear')\n                real_con2=interpolate(real_con2,scale_factor=2,mode='bilinear')\n                fake_con2_a=interpolate(self.fake_a,scale_factor=0.5,mode='bilinear')\n                fake_con2_a =interpolate(fake_con2_a, scale_factor=2, mode='bilinear')\n                loss_con2_a = self.lcon(fake_con2_a,real_con2.detach())\n                fake_con2_b = interpolate(self.fake_b, scale_factor=0.5, mode='bilinear')\n                fake_con2_b = interpolate(fake_con2_b, scale_factor=2, mode='bilinear')\n                loss_con2_b = self.lcon(fake_con2_b, real_con2.detach())\n                #64*64\n                real_con3 = interpolate(self.real_img, scale_factor=0.25, mode='bilinear')\n                real_con3 = interpolate(real_con3, scale_factor=4, mode='bilinear')\n                fake_con3_a = interpolate(self.fake_a, scale_factor=0.25, mode='bilinear')\n                fake_con3_a = interpolate(fake_con3_a, scale_factor=4, mode='bilinear')\n                loss_con3_a = self.lcon(fake_con3_a, real_con3.detach())\n                fake_con3_b = interpolate(self.fake_b, scale_factor=0.25, mode='bilinear')\n                fake_con3_b = interpolate(fake_con3_b, scale_factor=4, mode='bilinear')\n                loss_con3_b = self.lcon(fake_con3_a, real_con3.detach())\n                if not self.train_init:\n                    loss_G=fake_a_g_logit+fake_b_g_logit+(class_ga_logit+class_gb_logit)/2*self.lambda_cla+\\\n                               ((loss_con1_a+loss_con1_b)+(loss_con2_a+loss_con2_b)+(loss_con3_a+loss_con3_b))/3*self.lambda_con\n                else:\n                     loss_G=(loss_con1_a+loss_con1_b+loss_con2_a+loss_con2_b+loss_con3_a+loss_con3_b)/3*self.lambda_con\n                loss_G.backward()\n                self.G_optim.step()\n                end_time=t.time()\n                if self.train_init:\n                   print(f\"epoch:[{step}/{self.iter}],iter:[{i+1}/{count}],loss_G:{loss_G},G_lr:{self.G_optim.param_groups[0]['lr']},time:{time_change(end_time-start_time)}\")\n                else:\n                   print(f\"epoch[{step}/{self.iter}],iter[{i+1}/{count}],loss_G:{loss_G},loss_D1:{loss_D1},loss_D2:{loss_D2},time:{time_change(end_time-start_time)}\")\n            if step%self.save_pred==0:\n                train_sample_num=10\n                data_loader=self.load_data()\n                style1 = np.zeros((self.hw * 3, 0, 3))\n                style2 = np.zeros((self.hw * 3, 0, 3))\n                self.G.eval(),self.D1.eval(),self.D2.eval(),self.classifier.eval()\n                for _ in range(5):\n                    for i ,data in tqdm(enumerate(data_loader)):\n                        break\n                    real_img=data['source'].to(self.device)    \n                    real_A=data['TA'].to(self.device) \n                    real_B=data['TB'].to(self.device) \n                    fake_a,fake_b=self.Gen_pool_test(real_img)# 生成假图\n                    style1 = np.concatenate((style1, np.concatenate((RGB2BGR(denorm(real_img[0])),\n                                                                     RGB2BGR(denorm(real_A[0])),\n                                                                     RGB2BGR(denorm(fake_a[0]))),0)),1)\n                    style2 = np.concatenate((style2, np.concatenate((RGB2BGR(denorm(real_img[0])),\n                                                                     RGB2BGR(denorm(real_B[0])),\n                                                                     RGB2BGR(denorm(fake_b[0]))),0)),1)\n                cv2.imwrite(os.path.join(self.dir, self.dataset, 'img', 'style1_%06d.png' % step), style1)\n                cv2.imwrite(os.path.join(self.dir, self.dataset, 'img', 'style2_%06d.png' % step), style2)\n                print(\"测试图像生成成功！\")    \n                self.save_model()\n    #保存模型\n    def save_model(self):\n        params={}\n        params[\"G\"] = self.G.state_dict()\n        params[\"D1\"] = self.D1.state_dict()\n        params[\"D2\"] = self.D2.state_dict()\n        params[\"classifer\"] = self.classifier.state_dict()\n        torch.save(params, os.path.join(self.dir, self.dataset + 'cartoonmodel.pt'))\n        print(\"保存模型成功！\")\n    #加载模型\n    def load_model(self):\n        params = torch.load(os.path.join(self.test_path, 'cartooncartoonmodel.pt'))\n        self.G.load_state_dict(params['G'])\n#         self.D.load_state_dict(params['D'])\n        self.classifier.load_state_dict(params['classifer'])\n        print(\"加载模型成功！\")\n    #保存生成图像\n    def test(self):\n        self.load_model()\n        data_loader=self.load_data()\n        self.G.eval()\n        for i ,data in tqdm(enumerate(data_loader)):\n            real_img=data['source'].to(self.device)    \n            fake_a,fake_b=self.Gen_pool_test(real_img)# 生成假图\n            fake_a=RGB2BGR(denorm(fake_a[0]))\n            fake_b=RGB2BGR(denorm(fake_b[0]))\n            cv2.imwrite(os.path.join(self.dir, self.dataset, 'test/testA','style1_%06d.png' % i), fake_a)\n            cv2.imwrite(os.path.join(self.dir, self.dataset, 'test/testB','style2_%06d.png' % i), fake_b)\n            if i==100:\n                break\n        print(\"测试图像生成成功！\")    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import argparse\ndef parse_args():\n    desc='pytorch of MS-CartoonGAN'\n    parser=argparse.ArgumentParser(desc)\n    parser.add_argument('--device',type=str,default='cuda',choices=['cuda','cpu'])\n    parser.add_argument('--input_c', type=int, default=3)\n    parser.add_argument('--n_domain', type=int, default=2)\n    parser.add_argument('--n_class', type=int, default=3)\n    parser.add_argument('--pool_size', type=int, default=50)\n    parser.add_argument('--init_lr',type=float,default=0.0002)\n    parser.add_argument('--lr', type=float, default=0.00001, help='learning rate for ADAM')\n    parser.add_argument('--hw', type=int, default=256)\n    parser.add_argument('--mode', type=str, default='A')\n    parser.add_argument('--dir',type=str,default='result')\n    parser.add_argument('--dataset', type=str, default='cartoon')\n    parser.add_argument('--data_path',type=str,default='/kaggle/input/mscartoon/Cartoon/cartoon')\n    parser.add_argument('--test_path',type=str,default='/kaggle/input/model20d')\n    parser.add_argument('--isTrain',type=bool,default=True)\n    parser.add_argument('--retrain', type=bool, default=True)\n    parser.add_argument('--isTest', type=bool, default=False)\n    parser.add_argument('--train_init', type=bool, default=False)\n    parser.add_argument('--b1',type=int,default=0.5)\n    parser.add_argument('--b2', type=int, default=0.999)\n    parser.add_argument('--batch_size',type=int,default=4)\n    parser.add_argument('--save_pred',type=int,default=1)\n    parser.add_argument('--iter',type=int,default=25)\n    parser.add_argument('--weight_content',type=float,default=0.2)\n    parser.add_argument('--weight_decay', type=float, default=0.0001)\n    parser.add_argument('--weight_classifer', type=float, default=0.5)\n    return check_args(parser.parse_args(args=[]))\ndef check_args(args):\n    check_folder(os.path.join(args.dir, args.dataset, 'model'))\n    check_folder(os.path.join(args.dir, args.dataset, 'img'))\n    check_folder(os.path.join(args.dir, args.dataset, 'test'))\n    check_folder(os.path.join(args.dir, args.dataset, 'test','testA'))\n    check_folder(os.path.join(args.dir, args.dataset, 'test','testB'))\n    return args\ndef main():\n   args=parse_args()\n   gan=MSCartoonGAN(args)\n   if args.isTrain:\n       if args.retrain:\n            gan.load_model()\n       print(f\"training on {args.device}\")\n       gan.train()\n       print(\"train haved finished\")\n   if args.isTest:\n       gan.test()\n       print(\"test haved finished\")\nif __name__==\"__main__\":\n    main()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport zipfile\ndef file2zip(packagePath, zipPath):\n    zip = zipfile.ZipFile(zipPath, 'w', zipfile.ZIP_DEFLATED)\n    for path, dirNames, fileNames in os.walk(packagePath):\n        fpath = path.replace(packagePath, '')\n        for name in fileNames:\n            fullName = os.path.join(path, name)\n            name = fpath + '\\\\' + name\n            zip.write(fullName, name)\n    zip.close()\nif __name__ == \"__main__\":\n    # 文件夹路径\n    packagePath = './result/cartoon/test/testA'\n    zipPath = './model40AB.zip'\n    if os.path.exists(zipPath):\n        os.remove(zipPath)\n    file2zip(packagePath, zipPath)\n    print(\"打包完成\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}